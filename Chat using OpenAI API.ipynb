{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ba6108-588a-470b-8ea3-86521985ec4c",
   "metadata": {},
   "source": [
    "# Chat with PDFs using ChatGPT & OpenAI GPT API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1d5ed-de6d-4edb-8c02-5abe8631c5bd",
   "metadata": {},
   "source": [
    "This is a supplementary python notebook for the blog - https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api/. We dive into a detailed code tutorial on how to chat with all kinds of PDF files using OpenAI GPT API and use it for PDF automations / chatbots.\n",
    "\n",
    "* We will chat with PDFs using just a few lines of Python code.\n",
    "* We will chat with large PDF files using ChatGPT API and LangChain.\n",
    "* We will build an automation to sort PDF files based on their contents.\n",
    "* We will go through examples of building more automations for tasks involving PDFs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8b5d6-dc01-4ea3-a4aa-0b9065894da3",
   "metadata": {},
   "source": [
    "## Chat with PDF using ChatGPT API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49317bea-fcb7-4473-bf1c-1603ca18d67b",
   "metadata": {},
   "source": [
    "Let us now chat with our first PDF using OpenAI's GPT models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5ef09a-3a36-4e14-8477-6204a11e3495",
   "metadata": {},
   "source": [
    "We are going to converse with a resume PDF to demonstrate this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7057ed90-7e39-41e0-b2ef-fa92dba71b1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 1 - Read the PDF File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2820fd2c-62e2-4f9a-a45b-151222a7cc2b",
   "metadata": {},
   "source": [
    "We follow different approaches based on whether the PDF is scanned or digital."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01cea90-d384-4a2b-a7fa-8f00ccc21b1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Approach 1 : Read Digital PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cd36aa92-9c07-4c79-b107-0ac6b90b6e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTIONAL (EXPERIENCED)  \n",
      " \n",
      "IM A. SAMPLE I \n",
      "1234 North 55 Street \n",
      "Bellevue, Nebraska 68005  \n",
      "(402) 292-2345 \n",
      "imasample1@xxx.com  \n",
      " \n",
      "SUMMARY OF QUALIFICATIONS  \n",
      "Exceptionally well organized and resourceful  Professional with more than six years experience and a \n",
      "solid academic background in accounting and financial management; excellent analytical and problem \n",
      "solving skills; able to handle multiple projects while pr oducing high quality work in a fast -paced, \n",
      "deadline-oriented environment. \n",
      " \n",
      "EDUCATION \n",
      "Bachelor of Science, Bellevue University, Bellevue, NE (In Progress)  \n",
      " Major:  Accounting  Minor:  Computer Information Systems  \n",
      " Expected Graduation Date:  January, 20xx  GPA to date:  3.95/4.00 \n",
      " \n",
      "PROFESSIONAL ACCOMPLISHMENTS  \n",
      "Accounting and Financial Management  \n",
      " Developed and maintained accounting records for up to fifty bank accounts.  \n",
      " Formulated monthly and year -end financial statements and generated various payroll records, \n",
      "including federal and state payroll reports, annual tax reports, W -2 and 1099 forms, etc. \n",
      " Tested accuracy of account balances and prepared supporting documentation for submission during a \n",
      "comprehensive three-year audit of financial operations.  \n",
      " Formulated intricate pro-forma budgets. \n",
      " Calculated and implemented depreciation/amortization schedules.  \n",
      "Information Systems Analysis and Problem Solving  \n",
      " Converted manual to computerized accounting systems for two organizations.  \n",
      " Analyzed and successfully reprogrammed sof tware to meet customer requirements.  \n",
      " Researched and corrected problems to assure effective operation of newly computerized systems.  \n",
      " \n",
      "WORK HISTORY \n",
      "Student Intern, Financial Accounting Development Program, Mutual of Omaha, Omaha, NE  \n",
      "(Summer 20xx) \n",
      "Accounting Coordinator, Nebraska Special Olympics, Omaha, NE (20xx -20xx) \n",
      "Bookkeeper, SMC, Inc., Omaha, NE (20xx  – 20xx) \n",
      "Bookkeeper, First United Methodist Church, Altus, OK (20xx  – 20xx) \n",
      " \n",
      "PROFESSIONAL AFFILIATION \n",
      "Member, IMA, Bellevue University Student Chapter  \n",
      " \n",
      "COMPUTER SKILLS \n",
      " Proficient in MS Office (Word, Excel, PowerPoint, Outlook), QuickBooks  \n",
      " Basic Knowledge of MS Access, SQL, Visual Basic, C++  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "pdf_file_obj = open('resume-sample.pdf', 'rb')\n",
    "pdf_reader = PyPDF2.PdfFileReader(pdf_file_obj)\n",
    "num_pages = pdf_reader.numPages\n",
    "detected_text = ''\n",
    "\n",
    "for page_num in range(num_pages):\n",
    "    page_obj = pdf_reader.getPage(page_num)\n",
    "    detected_text += page_obj.extractText() + '\\n\\n'\n",
    "\n",
    "pdf_file_obj.close()\n",
    "\n",
    "print(detected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d902485-c9b3-4872-a093-6d06aad18cf2",
   "metadata": {},
   "source": [
    "##### Approach 2 : Read Scanned PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a7277de2-ca00-4ab5-8c9c-733d7ef0a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTIONAL (EXPERIENCED)\n",
      "\n",
      "IM A. SAMPLE I\n",
      "1234 North 55 Street\n",
      "Bellevue, Nebraska 68005\n",
      "(402) 292-2345\n",
      "imasamplel@xxx.com\n",
      "\n",
      "SUMMARY OF QUALIFICATIONS\n",
      "\n",
      "Exceptionally well organized and resourceful Professional with more than six years experience and a\n",
      "solid academic background in accounting and financial management; excellent analytical and problem\n",
      "solving skills; able to handle multiple projects while producing high quality work in a fast-paced,\n",
      "deadline-oriented environment.\n",
      "\n",
      "EDUCATION\n",
      "Bachelor of Science, Bellevue University, Bellevue, NE (In Progress)\n",
      "Major: Accounting Minor: Computer Information Systems\n",
      "Expected Graduation Date: January, 20xx GPA to date: 3.95/4.00\n",
      "\n",
      "PROFESSIONAL ACCOMPLISHMENTS\n",
      "\n",
      "Accounting and Financial Management\n",
      "\n",
      "e Developed and maintained accounting records for up to fifty bank accounts.\n",
      "\n",
      "e Formulated monthly and year-end financial statements and generated various payroll records,\n",
      "including federal and state payroll reports, annual tax reports, W-2 and 1099 forms, etc.\n",
      "\n",
      "e Tested accuracy of account balances and prepared supporting documentation for submission during a\n",
      "comprehensive three-year audit of financial operations.\n",
      "\n",
      "e Formulated intricate pro-forma budgets.\n",
      "\n",
      "e Calculated and implemented depreciation/amortization schedules.\n",
      "\n",
      "Information Systems Analysis and Problem Solving\n",
      "\n",
      "e Converted manual to computerized accounting systems for two organizations.\n",
      "\n",
      "e Analyzed and successfully reprogrammed software to meet customer requirements.\n",
      "\n",
      "e Researched and corrected problems to assure effective operation of newly computerized systems.\n",
      "\n",
      "WORK HISTORY\n",
      "\n",
      "Student Intern, Financial Accounting Development Program, Mutual of Omaha, Omaha, NE\n",
      "(Summer 20xx)\n",
      "\n",
      "Accounting Coordinator, Nebraska Special Olympics, Omaha, NE (20xx-20xx)\n",
      "Bookkeeper, SMC, Inc., Omaha, NE (20xx — 20xx)\n",
      "Bookkeeper, First United Methodist Church, Altus, OK (20xx — 20xx)\n",
      "\n",
      "PROFESSIONAL AFFILIATION\n",
      "Member, IMA, Bellevue University Student Chapter\n",
      "\n",
      "COMPUTER SKILLS\n",
      "\n",
      "e Proficient in MS Office (Word, Excel, PowerPoint, Outlook), QuickBooks\n",
      "e Basic Knowledge of MS Access, SQL, Visual Basic, C++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pdf2image\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "image = pdf2image.convert_from_path('resume-sample.pdf')\n",
    "for pagenumber, page in enumerate(image):\n",
    "    detected_text = pytesseract.image_to_string(page)\n",
    "    print(detected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058399a7-019a-4cbd-a276-a45b6d7a861d",
   "metadata": {},
   "source": [
    "#### Step 2 - First Chat with PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d602b7b-1335-49fe-a13a-2243e4af3a89",
   "metadata": {},
   "source": [
    "Let us ask the LLM to suggest jobs that this person will be suitable for based on his resume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a3256-3bbf-4653-927e-88e33b8fb56b",
   "metadata": {},
   "source": [
    "Firstly, We import the os and openai library and define our OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5e74c9f1-0fbb-4ffa-a296-44da367e6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = 'Your OpenAI API Key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04936e0-574b-42c6-a0b9-d8a8f83368d9",
   "metadata": {},
   "source": [
    "Choosing the ideal model while using OpenAI's python library depends on your use case and specific requirements. We recommend going through the list of available models and learning the pros and cons of each of the available models. You can access the list of available models as follows - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7bb9dc66-c557-4516-aa71-75bb3697c15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>owned_by</th>\n",
       "      <th>permission</th>\n",
       "      <th>root</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babbage</td>\n",
       "      <td>model</td>\n",
       "      <td>1649358449</td>\n",
       "      <td>openai</td>\n",
       "      <td>[{'id': 'modelperm-49FUp5v084tBB49tC4z8LPH5', ...</td>\n",
       "      <td>babbage</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>model</td>\n",
       "      <td>1669599635</td>\n",
       "      <td>openai-internal</td>\n",
       "      <td>[{'id': 'modelperm-jepinXYt59ncUQrjQEIUEDyC', ...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>davinci</td>\n",
       "      <td>model</td>\n",
       "      <td>1649359874</td>\n",
       "      <td>openai</td>\n",
       "      <td>[{'id': 'modelperm-U6ZwlyAd0LyMk4rcMdz33Yc3', ...</td>\n",
       "      <td>davinci</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text-davinci-edit-001</td>\n",
       "      <td>model</td>\n",
       "      <td>1649809179</td>\n",
       "      <td>openai</td>\n",
       "      <td>[{'id': 'modelperm-otmQSS0hmabtVGHI9QB3bct3', ...</td>\n",
       "      <td>text-davinci-edit-001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>babbage-code-search-code</td>\n",
       "      <td>model</td>\n",
       "      <td>1651172509</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>[{'id': 'modelperm-4qRnA3Hj8HIJbgo0cGbcmErn', ...</td>\n",
       "      <td>babbage-code-search-code</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text-similarity-babbage-001</td>\n",
       "      <td>model</td>\n",
       "      <td>1651172505</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>[{'id': 'modelperm-48kcCHhfzvnfY84OtJf5m8Cz', ...</td>\n",
       "      <td>text-similarity-babbage-001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>code-davinci-edit-001</td>\n",
       "      <td>model</td>\n",
       "      <td>1649880484</td>\n",
       "      <td>openai</td>\n",
       "      <td>[{'id': 'modelperm-Foe5Y4TvaKveYxt74oKMw8IB', ...</td>\n",
       "      <td>code-davinci-edit-001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ada</td>\n",
       "      <td>model</td>\n",
       "      <td>1649357491</td>\n",
       "      <td>openai</td>\n",
       "      <td>[{'id': 'modelperm-u0nKN4ub7EVQudgMuvCuvDjc', ...</td>\n",
       "      <td>ada</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>babbage-code-search-text</td>\n",
       "      <td>model</td>\n",
       "      <td>1651172509</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>[{'id': 'modelperm-Lftf8H4ZPDxNxVs0hHPJBUoe', ...</td>\n",
       "      <td>babbage-code-search-text</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>babbage-similarity</td>\n",
       "      <td>model</td>\n",
       "      <td>1651172505</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>[{'id': 'modelperm-mS20lnPqhebTaFPrcCufyg7m', ...</td>\n",
       "      <td>babbage-similarity</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id object     created         owned_by  \\\n",
       "0                      babbage  model  1649358449           openai   \n",
       "1             text-davinci-003  model  1669599635  openai-internal   \n",
       "2                      davinci  model  1649359874           openai   \n",
       "3        text-davinci-edit-001  model  1649809179           openai   \n",
       "4     babbage-code-search-code  model  1651172509       openai-dev   \n",
       "5  text-similarity-babbage-001  model  1651172505       openai-dev   \n",
       "6        code-davinci-edit-001  model  1649880484           openai   \n",
       "7                          ada  model  1649357491           openai   \n",
       "8     babbage-code-search-text  model  1651172509       openai-dev   \n",
       "9           babbage-similarity  model  1651172505       openai-dev   \n",
       "\n",
       "                                          permission  \\\n",
       "0  [{'id': 'modelperm-49FUp5v084tBB49tC4z8LPH5', ...   \n",
       "1  [{'id': 'modelperm-jepinXYt59ncUQrjQEIUEDyC', ...   \n",
       "2  [{'id': 'modelperm-U6ZwlyAd0LyMk4rcMdz33Yc3', ...   \n",
       "3  [{'id': 'modelperm-otmQSS0hmabtVGHI9QB3bct3', ...   \n",
       "4  [{'id': 'modelperm-4qRnA3Hj8HIJbgo0cGbcmErn', ...   \n",
       "5  [{'id': 'modelperm-48kcCHhfzvnfY84OtJf5m8Cz', ...   \n",
       "6  [{'id': 'modelperm-Foe5Y4TvaKveYxt74oKMw8IB', ...   \n",
       "7  [{'id': 'modelperm-u0nKN4ub7EVQudgMuvCuvDjc', ...   \n",
       "8  [{'id': 'modelperm-Lftf8H4ZPDxNxVs0hHPJBUoe', ...   \n",
       "9  [{'id': 'modelperm-mS20lnPqhebTaFPrcCufyg7m', ...   \n",
       "\n",
       "                          root parent  \n",
       "0                      babbage   None  \n",
       "1             text-davinci-003   None  \n",
       "2                      davinci   None  \n",
       "3        text-davinci-edit-001   None  \n",
       "4     babbage-code-search-code   None  \n",
       "5  text-similarity-babbage-001   None  \n",
       "6        code-davinci-edit-001   None  \n",
       "7                          ada   None  \n",
       "8     babbage-code-search-text   None  \n",
       "9           babbage-similarity   None  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "models = openai.Model.list()\n",
    "modelsdf = pd.DataFrame(models[\"data\"])\n",
    "modelsdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293ab193-5ecd-48d4-a4b6-d4353262a80c",
   "metadata": {},
   "source": [
    "Next, we append our query - \"give a list of jobs suitable for the above resume\" to the extracted PDF text and send this as the user_msg. The detected_text variable already contains the data extracted from the PDF. We will simply append our query here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5d225142-7b7d-4ca2-9acb-b7fd32eb22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'give a list of jobs suitable for the above resume.'\n",
    "\n",
    "user_msg = detected_text + '\\n\\n' + query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be3b7e7-20a3-4930-bb66-fa6c9fdd6dc1",
   "metadata": {},
   "source": [
    "We also add a relevant system_msg to refine the behavior of the AI assistant. In our case, a useful system message can be \"You are a helpful career advisor.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "10d5ca7a-9d31-4eb4-88ef-ac836fa3a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = 'You are a helpful career advisor.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cc733f-b44c-46f3-a975-c6462b116c3a",
   "metadata": {},
   "source": [
    "We send the request to get our first response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e63bb745-1e83-4e0b-a59e-03b9e08e004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "                    {\"role\": \"user\", \"content\": user_msg}]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b908b03-b3f8-4493-8c7b-5ed9b4b12048",
   "metadata": {},
   "source": [
    "Once the request is complete, the response object will contain the response from the LLM. We can view it by accessing the 'choices' attribute in the response object as follows -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c65372e2-17e4-4f25-ad14-c7225f89e0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Accountant: This candidate has a strong background in accounting and financial management, including experience in maintaining accounting records, preparing financial statements, and managing payroll. They would be well-suited for a role as an accountant, handling financial tasks for a company or organization.\n",
      "\n",
      "2. Financial Analyst: With their excellent analytical and problem-solving skills, this candidate could excel in a role as a financial analyst. They have experience in creating budgets, analyzing financial data, and preparing reports. They would be valuable in helping organizations make informed decisions based on financial information.\n",
      "\n",
      "3. Bookkeeper: The candidate has experience as a bookkeeper and has successfully managed financial records for multiple organizations. They are proficient in QuickBooks and have knowledge of other accounting software. This makes them a good fit for a bookkeeping role, maintaining accurate financial records and handling day-to-day financial transactions.\n",
      "\n",
      "4. Financial Accounting Intern: Given their experience as a student intern in a financial accounting development program, this candidate could be a strong fit for similar internship positions. They would benefit from further hands-on experience and training in the field of financial accounting.\n",
      "\n",
      "5. Financial Systems Analyst: With their experience in converting manual to computerized accounting systems and successfully reprogramming software, this candidate has the skills to work as a financial systems analyst. They could help organizations optimize their financial systems, troubleshoot issues, and ensure effective operation.\n",
      "\n",
      "6. Financial Planner: This candidate's understanding of accounting, financial management, and analytical skills could make them a good fit for a role as a financial planner. They would be able to analyze clients' financial situations, develop comprehensive financial plans, and provide advice on investments, retirement planning, and other financial matters.\n",
      "\n",
      "7. Auditor: With their experience in preparing supporting documentation for audits and their attention to detail, this candidate could work as an auditor. They would be responsible for reviewing financial records, ensuring compliance, and identifying any potential errors or issues.\n",
      "\n",
      "8. Accounting Coordinator: This candidate's experience as an accounting coordinator for a non-profit organization showcases their ability to handle various accounting tasks. They would be suitable for similar coordinator roles, ensuring smooth financial operations within an organization and collaborating with different departments.\n",
      "\n",
      "9. Financial Assistant: This candidate's strong organizational skills and ability to handle multiple projects could make them a good fit for a financial assistant role. They would support financial professionals with various tasks, such as analyzing financial data, preparing reports, and managing financial documents.\n",
      "\n",
      "10. Financial Systems Support Specialist: With their experience in researching and correcting issues with computerized accounting systems, this candidate would be well-suited for a role as a financial systems support specialist. They would help troubleshoot problems and provide technical support to ensure the smooth operation of financial software and systems.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c13aec-3949-4cc3-a1cc-423247d2b1df",
   "metadata": {},
   "source": [
    "#### Step 3 : Continuing the Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d9a9a3-9fea-4d39-b71c-5697ef868863",
   "metadata": {},
   "source": [
    "Often, we would want to have conversations with the LLM which are more than just a pair of a single prompt and a single response. Let us now learn how to use our past conversation history to continue the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4239ad3-27b1-4a47-a092-005132d5e991",
   "metadata": {},
   "source": [
    "To simplify the implementation, we define the following function for calling the OpenAI GPT API from now on -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ee6681b7-d81d-4f23-9508-0852ae81ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_chat(system_message, user_assistant_messages):\n",
    "  \n",
    "  system_msg = [{\"role\": \"system\", \"content\": system_message}]\n",
    "  \n",
    "  user_assistant_msgs = [{\"role\": \"assistant\", \"content\": user_assistant_messages[i]} if i % 2 else {\"role\": \"user\", \"content\": user_assistant_messages[i]} for i in range(len(user_assistant_messages))]\n",
    "\n",
    "  allmsgs = system_msg + user_assistant_msgs\n",
    "  response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                          messages=allmsgs)\n",
    "  \n",
    "  return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb502de-47c6-48d4-9768-f85d202a8619",
   "metadata": {},
   "source": [
    "The function accepts -\n",
    "\n",
    "* system_message (string) : This acts as the system_msg\n",
    "* user_assistant_messages (list) : This list contains user prompts and model responses in alternating order. This is also the order in which they occur in the conversation.\n",
    "\n",
    "The function internally makes the API call to generate and return a new response based on the conversation history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10e06-53f9-4f3a-a903-abc1252e07f8",
   "metadata": {},
   "source": [
    "Let us now use this function to continue our previous conversation, and find out the highest paying jobs out of the ones recommended in the first response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f299e-6cc6-4a75-bb9c-44bd309fb2e8",
   "metadata": {},
   "source": [
    "We will use the same system message (system_msg) used in previous call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef1646-2c25-47cd-9952-001d0034f98d",
   "metadata": {},
   "source": [
    "We create user_assistant_messages list as follows - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7da14a5e-ef43-4e5e-9ff5-9aeee2657620",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_msg1 = user_msg\n",
    "model_response1 = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "user_msg2 = 'based on the suggestions, choose the 3 jobs with highest average salary'\n",
    "user_assistant_msgs = [user_msg1, model_response1, user_msg2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5818d1-85f5-4d59-a6e6-84fa5f92a964",
   "metadata": {},
   "source": [
    "Note that we used the original prompt as the first user message (user_msg1), the response to that prompt as the first model response message (model_response1), and our new prompt as the second user message (user_msg2).\n",
    "\n",
    "Finally, we add them to the user_assistant_messages list in order of their occurrence in the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019ff2a6-b81c-4213-a9a2-2bb68d6ec16f",
   "metadata": {},
   "source": [
    "We now call the continue_chat() function to get the next response in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e4946e85-abe9-43e3-8ce6-75be57a91cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = continue_chat(system_msg, user_assistant_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "18388927-b53e-4b69-8f53-b8d120da1851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the suggestions provided, the three jobs with the highest average salary potential are:\n",
      "\n",
      "1. Financial Analyst: Financial analysts typically earn a good salary, with the potential to earn higher compensation as they gain experience and advance in their careers. The median annual wage for financial analysts in the United States was $81,590 in May 2020, according to the Bureau of Labor Statistics.\n",
      "\n",
      "2. Auditor: Auditors play a crucial role in ensuring financial accuracy and compliance, and they are often compensated well for their expertise. The median annual wage for auditors and accountants in the United States was $73,560 in May 2020, according to the Bureau of Labor Statistics.\n",
      "\n",
      "3. Financial Planner: Financial planners help individuals and families manage their finances and plan for the future. With their knowledge and expertise, financial planners have the potential to earn a high salary. The median annual wage for personal financial advisors, which includes financial planners, was $89,330 in May 2020, according to the Bureau of Labor Statistics.\n",
      "\n",
      "It's important to note that salaries can vary depending on factors such as location, level of experience, and industry. These figures are just general averages and individual salaries may vary.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0aa66a-6707-4c33-9995-58b63d06340c",
   "metadata": {},
   "source": [
    "## Chat with Large PDFs using ChatGPT API and LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb9b7ce-05a2-458c-b9b6-5b98b07d4173",
   "metadata": {},
   "source": [
    "The code tutorial shown above fails for very large PDFs. Let us illustrate this with an example. We will try to chat with BCG's \"2022 Annual Sustainability Report\", a large PDF published by the Boston Consulting Group (BCG) on their general impact in the industry. We execute the code shown below -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fc1dfb47-ef56-4a75-a2a4-1423a00d1583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251907\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "pdf_file_obj = open('bcg-2022-annual-sustainability-report-apr-2023.pdf', 'rb')\n",
    "pdf_reader = PyPDF2.PdfFileReader(pdf_file_obj)\n",
    "num_pages = pdf_reader.numPages\n",
    "detected_text = ''\n",
    "\n",
    "for page_num in range(num_pages):\n",
    "    page_obj = pdf_reader.getPage(page_num)\n",
    "    detected_text += page_obj.extractText() + '\\n\\n'\n",
    "\n",
    "pdf_file_obj.close()\n",
    "print(len(detected_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d084d-04f5-4880-85f9-cb3ae664a7c0",
   "metadata": {},
   "source": [
    "We can see that the PDF is super large, and the length of the detected_text string variable is roughly 250k.\n",
    "\n",
    "Let us now try chatting with the PDF -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "972c4d72-ab03-4b06-afdb-5a3b37aa5985",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, your messages resulted in 54696 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [108]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124msummarize this PDF in 500 words.\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      7\u001b[0m user_msg \u001b[38;5;241m=\u001b[39m detected_text \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m query\n\u001b[0;32m----> 9\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_msg\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_msg\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 54696 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "system_msg = ''\n",
    "\n",
    "query = '''\n",
    "summarize this PDF in 500 words.\n",
    "'''\n",
    "\n",
    "user_msg = detected_text + '\\n\\n' + query\n",
    "\n",
    "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                        messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "                                         {\"role\": \"user\", \"content\": user_msg}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b64e1-ad09-4aa3-a633-9e2a9ae9bd18",
   "metadata": {},
   "source": [
    "We get an error message saying that we have hit the prompt length threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364eebdc-44b9-4d49-a0fb-ec0216620db6",
   "metadata": {},
   "source": [
    "This happens because for large PDFs with lots of text, the request payload we send to OpenAI becomes too large, and OpenAI returns an error saying that we have hit the prompt length threshold.\n",
    "\n",
    "Let us now learn how to remove this bottleneck.\n",
    "\n",
    "Enter LangChain. LangChain is an innovative technology that functions as a bridge -  linking large language models (LLMs) with practical applications like Python programming, PDFs, CSV files, or databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133610e2-7f07-4c12-9f97-f4ddabd6954e",
   "metadata": {},
   "source": [
    "Let us import the required dependencies and get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1c49eb2b-3708-4926-b0bd-4b38d901a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c464f6f9-1c02-448f-a8e9-374e896cb8e7",
   "metadata": {},
   "source": [
    "We load the PDF using PyPDF loader for LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f133dabb-cffa-4488-bfa2-2eaefe6eb513",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"bcg-2022-annual-sustainability-report-apr-2023.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c1956-221f-47ab-9628-cf1911da53fd",
   "metadata": {},
   "source": [
    "We will perform chunking and split the text using LangChain text splitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fd94780d-8814-4991-a245-cee2019e2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.create_documents([detected_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f5ad8-22a1-4892-8061-6a49879ae312",
   "metadata": {},
   "source": [
    "We create a vector database using the chunks. We will save it the database for future use as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f777e-a3c8-4f92-ba74-87664c62748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'index_store'\n",
    "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "vector_index.save_local(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798c771-1a80-4dc7-8554-dec20b73c628",
   "metadata": {
    "tags": []
   },
   "source": [
    "We now load the database. Using the database, we configure a retriever and then create a chat object. This chat object (qa_interface) will be used to chat with the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d8625c8b-8cb4-4893-8c2b-0a7686ad359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = FAISS.load_local('index_store', OpenAIEmbeddings())\n",
    "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":6})\n",
    "qa_interface = RetrievalQA.from_chain_type(llm=ChatOpenAI(), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba03911-8774-428a-818d-471290ae5379",
   "metadata": {},
   "source": [
    "We can now start chatting with the PDF. Let us ask the PDF to list measures taken to address diseases occurring in developing industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d7ec8058-5ca5-463b-bca0-d82655fe927e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = qa_interface(\"List measures taken to address diseases occuring in developing industries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8ba31977-c58a-4ce9-9e02-ca10441abfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the following measures have been taken to address diseases occurring in developing countries:\n",
      "\n",
      "1. Accord for a Healthier World: Pfizer has initiated the \"Accord for a Healthier World\" program to provide access to innovative medicines to people living in 45 lower-income countries. This program aims to improve the health of up to 1.2 billion people affected by deadly infectious diseases, cancers, and inflammatory diseases.\n",
      "\n",
      "2. Expansion of access to medicines and vaccines: The Accord for a Healthier World aims to extend access to the full portfolio of medicines and vaccines to all eligible individuals in lower-income countries. This expansion of access can help in addressing diseases occurring in these regions.\n",
      "\n",
      "3. Private sector engagement: Private sector engagement is seen as critical in driving implementation and addressing diseases. Private sources can contribute funding to unlock returns and support implementation through innovative solutions.\n",
      "\n",
      "4. Comprehensive A&R systems: The establishment of comprehensive A&R (Adaptation and Resilience) systems can help countries respond and adapt to health crises. Cities like Lagos are mentioned as potential leaders in this aspect.\n",
      "\n",
      "It is important to note that the provided context does not specify measures taken specifically for diseases occurring in developing industries. However, the mentioned initiatives and approaches can contribute to addressing diseases in developing countries as a whole.\n"
     ]
    }
   ],
   "source": [
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98144ad4-c83b-457d-a218-d83fcf2d87fd",
   "metadata": {},
   "source": [
    "So far, we've used the RetrievalQA chain, a LangChain type for pulling document pieces from a vector store and asking one question about them. But, sometimes we need to have a full conversation about a document, including referring to topics we've already talked about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d89fa5-8647-4c60-9900-ce80e63e5edf",
   "metadata": {},
   "source": [
    "Thankfully, LangChain has us covered. To make this possible, our system needs a memory or conversation history.  Instead of the RetrievalQA chain, we'll use the ConversationalRetrievalChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "333f16b7-d173-4e71-9754-c7afab10afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_interface = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0), retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949d78f-9e99-457f-a78b-8b4ad86d926f",
   "metadata": {},
   "source": [
    "Let's ask the PDF to reveal the context in which Morocco is mentioned in the report.\n",
    "\n",
    "'chat_history' parameter is a list contains past conversation history. For the first message, this list will be empty.\n",
    "\n",
    "'question' parameter is used to send our message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "beea0fa8-ef31-4e8d-be1f-7606d17db122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morocco is mentioned in the report in the context of social protection reforms and the extension of the social safety net. The government of Morocco announced a transformational sweep of social reforms, including the expansion of universal health care coverage. BCG collaborated with the government to model scenarios for expanding child support, extending the country's pension scheme and unemployment benefits, and instituting other reforms. The report highlights the positive outcomes of these social protection reforms in Morocco, such as increased access to health care for the population.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"in what context is Morocco mentioned in the report?\"\n",
    "result = conv_interface({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e09a97-ceee-4320-a5f3-15dbce7bb1ed",
   "metadata": {},
   "source": [
    "Let us now continue the conversation by updating the chat_history variable and ask the PDF to give some statistics around this. We append the messages in order of appearance in the conversation. We first append our initial message followed by the first response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4cef65d2-2a17-4b22-811e-d1e3cc386654",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append((query, result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854acef-2c8c-4518-91d8-97b16d11d0fa",
   "metadata": {},
   "source": [
    "We now add our new question along with the updated chat_history to continue the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d2f84982-b5f7-4f38-8ff2-9e73663faa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the report, as of December 1, 2022, more than 90% of Morocco's population now has access to universal health care, which is a significant increase from 42% just months before. This expansion has enabled millions of vulnerable families to benefit from improved health access. Additionally, around 10 million of Morocco's most vulnerable people now have improved access to healthcare.\n"
     ]
    }
   ],
   "source": [
    "query = \"give some statistics around this.\"\n",
    "result = conv_interface({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9955e9-2404-456c-a77d-ebd7073eefe4",
   "metadata": {},
   "source": [
    "The result uses the context gained by knowing the conversation history, and provides another great response! We can keep updating the chat_history variable and further continue our conversation using this method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ddf19-3634-4554-b9a0-22fcaa15eef8",
   "metadata": {},
   "source": [
    "## Build PDF Automations using OpenAI GPT API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f422d523-b6ca-4cab-b815-9003eb8fe392",
   "metadata": {},
   "source": [
    "Let us now explore automations involving PDF tasks that can be implemented using GPT API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4688353d-83fb-4009-b07c-69d51224d17f",
   "metadata": {},
   "source": [
    "#### Automation 1 - Document Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ee803-ee65-4847-bd0a-b1238b4089ae",
   "metadata": {},
   "source": [
    "GPT-3.5 is excellent at extracting data from documents. Let us try to extract data from an invoice using it. We are going to extract the following fields in JSON format - invoice_date, invoice_number, seller_name, seller_address, total_amount, and each line item present in the invoice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7f7d3f4-57fc-44b7-b5cc-91ad48ff12f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"invoice_date\": \"May 24th, 2024\",\n",
      "  \"invoice_number\": \"12345\",\n",
      "  \"seller_name\": \"Anvil Co\",\n",
      "  \"seller_address\": \"123 Main Street, San Francisco CA, 94103\",\n",
      "  \"total_amount\": \"$105.00\",\n",
      "  \"line_items\": [\n",
      "    {\n",
      "      \"description\": \"2 Blue large widgets\",\n",
      "      \"price\": \"$15.00\",\n",
      "      \"subtotal\": \"$30.00\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"4 Green medium widgets\",\n",
      "      \"price\": \"$10.00\",\n",
      "      \"subtotal\": \"$40.00\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"5 Red small widgets with logo\",\n",
      "      \"price\": \"$7.00\",\n",
      "      \"subtotal\": \"$35.00\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = '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'\n",
    "\n",
    "import pdf2image\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "image = pdf2image.convert_from_path('invoice.pdf')\n",
    "for pagenumber, page in enumerate(image):\n",
    "    detected_text = pytesseract.image_to_string(page)\n",
    "    \n",
    "system_msg = 'You are an invoice processing solution.'\n",
    "\n",
    "query = '''\n",
    "extract data from above invoice and return only the json containing the following -\n",
    "invoice_date, invoice_number, seller_name, seller_address, total_amount, and each line item present in the invoice.\n",
    "json=\n",
    "'''\n",
    "\n",
    "user_msg = detected_text + '\\n\\n' + query\n",
    "\n",
    "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                        messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "                                         {\"role\": \"user\", \"content\": user_msg}])\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c475d48-81cd-4608-9800-0e61dffec99f",
   "metadata": {},
   "source": [
    "The json here is essentially a json dump - it is a text string which is in the correct json format, but is not a json variable yet.\n",
    "\n",
    "Let us convert this response to a json variable, which happens by adding just one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aef0fe-705d-48a1-a375-d257f2b5b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "invoice_json = json.loads(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "03085da9-53b1-43bb-93ae-f1a9c5d394be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"invoice_date\": \"May 24th, 2024\",\n",
      "  \"invoice_number\": \"12345\",\n",
      "  \"seller_name\": \"Anvil Co\",\n",
      "  \"seller_address\": \"123 Main Street, San Francisco CA, 94103\",\n",
      "  \"total_amount\": \"$105.00\",\n",
      "  \"line_items\": [\n",
      "    {\n",
      "      \"description\": \"2 Blue large widgets\",\n",
      "      \"price\": \"$15.00\",\n",
      "      \"subtotal\": \"$30.00\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"4 Green medium widgets\",\n",
      "      \"price\": \"$10.00\",\n",
      "      \"subtotal\": \"$40.00\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"5 Red small widgets with logo\",\n",
      "      \"price\": \"$7.00\",\n",
      "      \"subtotal\": \"$35.00\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pretty_json = json.dumps(invoice_json, indent=2)\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc1c40f-b279-4019-96e9-fc82708a7b6a",
   "metadata": {},
   "source": [
    "#### Automation 2 - Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f6647-52c5-4dde-8fb8-67f458bdd861",
   "metadata": {},
   "source": [
    "Let us consider an example. Say we have a lot of files which are either invoices or receipts. We want to classify and sort these documents based on their type.\n",
    "\n",
    "Doing this is easy using GPT API.\n",
    "\n",
    "We create simple python functions to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b102e366-6a1c-4266-9da0-6d9ec447f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = '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'\n",
    "\n",
    "\n",
    "def list_files_only(directory_path):\n",
    "    if os.path.isdir(directory_path):\n",
    "        file_list = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "        file_list = [file for file in file_list if \".pdf\" in file]\n",
    "        return file_list\n",
    "    else:\n",
    "        return f\"{directory_path} is not a directory\"\n",
    "\n",
    "def classify(file_name):\n",
    "    \n",
    "    image = pdf2image.convert_from_path(file_name)\n",
    "    for pagenumber, page in enumerate(image):\n",
    "        detected_text = pytesseract.image_to_string(page)\n",
    "    \n",
    "    system_msg = 'You are an accounts payable expert.'\n",
    "\n",
    "    query = '''\n",
    "    Classify this document and return one of these two document types as response - [Invoices, Receipts]\n",
    "    Return only the document type in the response.\n",
    "\n",
    "    Document Type = \n",
    "    '''\n",
    "\n",
    "    user_msg = detected_text + '\\n\\n' + query\n",
    "\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "                                             {\"role\": \"user\", \"content\": user_msg}])\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def move_file(current_path, new_folder):\n",
    "    if os.path.isfile(current_path) and os.path.isdir(new_folder):\n",
    "        file_name = os.path.basename(current_path)\n",
    "        new_path = os.path.join(new_folder, file_name)\n",
    "        shutil.move(current_path, new_path)\n",
    "        print(f'File moved to {new_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8e4a0-2b9e-475a-8e1a-51b97b5b77e7",
   "metadata": {},
   "source": [
    "We create two folders labelled 'Invoices' & 'Receipts', in the folder where the unclassified invoices & receipts are present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27097f34-7bbe-46d1-9dd7-65db903725e2",
   "metadata": {},
   "source": [
    "Let us execute the code now to classify these files and sort them into separate folders based on the document type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6f03846c-25b1-46e8-a166-2e6e58412f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File moved to invoices and receipts/Invoices/sample 8.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 9.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 11.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 10.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 12.pdf\n",
      "File moved to invoices and receipts/Receipts/sample 13.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 17.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 16.pdf\n",
      "File moved to invoices and receipts/Receipts/sample 15.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 18.pdf\n",
      "File moved to invoices and receipts/Receipts/sample 21.pdf\n",
      "File moved to invoices and receipts/Receipts/sample 20.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 2.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 3.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 1.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 4.pdf\n",
      "File moved to invoices and receipts/Receipts/sample 5.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 7.pdf\n",
      "File moved to invoices and receipts/Invoices/sample 6.pdf\n"
     ]
    }
   ],
   "source": [
    "list_of_files = list_files_only('invoices and receipts/')\n",
    "for doc in list_of_files:\n",
    "    current_path = 'invoices and receipts/' + doc\n",
    "    doc_type = classify(current_path)\n",
    "    new_path = 'invoices and receipts/' + doc_type\n",
    "    move_file(current_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a55430-b88c-4d3a-bbc9-6e67f0f6051b",
   "metadata": {},
   "source": [
    "Upon execution, the code sorts these files perfectly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b610220-b182-4edb-8cf4-ed2c640daeb6",
   "metadata": {},
   "source": [
    "#### Automation 3 - Recipe Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ecc623-9789-4a51-9454-d3a1beb98395",
   "metadata": {},
   "source": [
    "We can even feed our favorite cookbooks to GPT API, and ask it to give recipe recommendations based on our inputs. Let us look at an example. We use the Brakes' Meals n More recipe cookbook, and talk to it using LangChain. Let us ask it to give recommendations based on the ingredients we have at home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d3d44353-9b08-4d09-82c0-dde36470bd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, here is a recipe you can make using broccoli and tomatoes:\n",
      "\n",
      "Vegetable Korma\n",
      "\n",
      "Serves: 10\n",
      "\n",
      "Ingredients:\n",
      "- 800g Broccoli\n",
      "- 800g Chopped Tomatoes (in tomato juice)\n",
      "- 30ml Sunflower Oil\n",
      "- 40g Mild Chilli Powder\n",
      "- 2ea Red Peppers\n",
      "- 25g Vegetable Bouillon Mix (Check ingredient list for allergens)\n",
      "- 500ml Water\n",
      "\n",
      "Getting ready:\n",
      "1. Wash and chop the broccoli into florets\n",
      "2. Dice the red peppers\n",
      "\n",
      "Method:\n",
      "1. In a large pan, heat the sunflower oil and sauté the broccoli and red peppers for about 5 minutes.\n",
      "2. Add the chopped tomatoes and vegetable bouillon mix to the pan, along with the water. Stir well.\n",
      "3. Sprinkle in the mild chili powder and mix everything together.\n",
      "4. Allow the korma to simmer for about 20-25 minutes, or until the broccoli is cooked to your liking.\n",
      "5. Serve with rice or naan bread.\n",
      "\n",
      "Please note that this recipe is based on the given context and may need to be adjusted to suit your personal taste preferences.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "directory = 'index_store'\n",
    "\n",
    "loader = PyPDFLoader(\"meals-more-recipes.pdf\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.create_documents([detected_text])\n",
    "\n",
    "directory = 'index_store'\n",
    "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "vector_index.save_local(directory)\n",
    "\n",
    "vector_index = FAISS.load_local('index_store', OpenAIEmbeddings())\n",
    "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":6})\n",
    "qa_interface = RetrievalQA.from_chain_type(llm=ChatOpenAI(), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "\n",
    "response = qa_interface(\"\"\"\n",
    "I have a lot of broccoli and tomatoes at home. \n",
    "Recommend recipe for some meal I can make at home using these.\n",
    "\"\"\")\n",
    "\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e188d-e9f1-40b5-950f-f9aeb4d7121f",
   "metadata": {},
   "source": [
    "Upon execution, the PDF recommends a recipe for a meal that can be prepared using the mentioned ingredients!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f154b91-9bde-463b-a584-ebe146902efc",
   "metadata": {},
   "source": [
    "#### Automation 4 - Automated Test Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85030b2-0966-486d-854a-95d2bdc9d771",
   "metadata": {},
   "source": [
    "You can feed textbooks and automate creation of complete question papers and tests using GPT API. The LLM can even generate the marking scheme for you!\n",
    "We use the textbook Advanced High-School Mathematics by David B. Surowski and ask the LLM to create a question paper with a marking scheme for a particular chapter in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35da741-fc85-40b1-ae29-8d70a6e47738",
   "metadata": {},
   "source": [
    "We execute the below code - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ef0d9202-2058-4fb5-a859-5bf213673789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Prove that the diagonals of a parallelogram bisect each other.\n",
      "(Weightage: 5 marks, Difficulty: Medium)\n",
      "\n",
      "2. Show that in a right-angled triangle, the square of the hypotenuse is equal to the sum of the squares of the other two sides.\n",
      "(Weightage: 6 marks, Difficulty: Medium)\n",
      "\n",
      "3. Prove that the opposite angles of a cyclic quadrilateral are supplementary.\n",
      "(Weightage: 4 marks, Difficulty: Easy)\n",
      "\n",
      "4. In a triangle ABC, prove that the medians intersect at a point which divides each median in the ratio 2:1.\n",
      "(Weightage: 3 marks, Difficulty: Easy)\n",
      "\n",
      "5. Given two parallel lines and a transversal, prove that the alternate interior angles are congruent.\n",
      "(Weightage: 2 marks, Difficulty: Easy)\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "directory = 'index_store'\n",
    "\n",
    "loader = PyPDFLoader(\"further.pdf\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.create_documents([detected_text])\n",
    "\n",
    "directory = 'index_store'\n",
    "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "vector_index.save_local(directory)\n",
    "\n",
    "vector_index = FAISS.load_local('index_store', OpenAIEmbeddings())\n",
    "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":6})\n",
    "qa_interface = RetrievalQA.from_chain_type(llm=ChatOpenAI(), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "\n",
    "response = qa_interface(\"\"\"\n",
    "list 5 questions of 20 marks total of varying difficuly and weightage based on the topic \"Euclidian Geometry\"\n",
    "\"\"\")\n",
    "\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f36101-9ae6-4854-8912-341873902998",
   "metadata": {},
   "source": [
    "The LLM reads the PDF textbook and create the question paper for us!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
